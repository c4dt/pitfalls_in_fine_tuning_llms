{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ad116-ccf9-4cf1-9a4d-8a5ebf7419f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import gc\n",
    "\n",
    "# third party imports\n",
    "import numpy\n",
    "import torch\n",
    "import pandas\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# local imports\n",
    "import share\n",
    "import evaluation\n",
    "\n",
    "\n",
    "TEST_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c7127-efbb-4e43-a739-586818383f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 fine-tuned on SetFit/enron_spam\n",
    "\n",
    "# fine-tuning benchmarks\n",
    "\n",
    "figure, axes = matplotlib.pyplot.subplots(nrows=3, ncols=2)\n",
    "\n",
    "# LoRA\n",
    "# https://github.com/Lightning-AI/litgpt/pull/587#issue-1914239351\n",
    "rows = pandas.read_csv(share.LLAMA2_ENRON_SPAM_LORA_LOGS).groupby(\"step\").sum()\n",
    "axes[0][0].set_title(\"LoRA\")\n",
    "axes[0][1].set_title(\"LoRA\")\n",
    "rows.iloc[1::, :].plot(y=\"loss\", ax=axes[0][0])\n",
    "rows.iloc[0::800, :].plot(y=\"val_loss\", ax=axes[0][1], color=\"orange\")\n",
    "\n",
    "# QLoRA\n",
    "rows = pandas.read_csv(share.LLAMA2_ENRON_SPAM_QLORA_LOGS).groupby(\"step\").sum()\n",
    "axes[1][0].set_title(\"QLoRA\")\n",
    "axes[1][1].set_title(\"QLoRA\")\n",
    "rows.iloc[1::, :].plot(y=\"loss\", ax=axes[1][0])\n",
    "rows.iloc[0::800, :].plot(y=\"val_loss\", ax=axes[1][1], color=\"orange\")\n",
    "\n",
    "# full parameter\n",
    "rows = pandas.read_csv(share.LLAMA2_ENRON_SPAM_FULL_LOGS).groupby(\"step\").sum()\n",
    "axes[2][0].set_title(\"full parameter\")\n",
    "axes[2][1].set_title(\"full parameter\")\n",
    "rows.iloc[1::, :].plot(y=\"loss\", ax=axes[2][0])\n",
    "rows.iloc[0::800, :].plot(y=\"val_loss\", ax=axes[2][1], color=\"orange\")\n",
    "\n",
    "figure.tight_layout()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36396000-29e6-46ac-975b-5626c258e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 fine-tuned on iamtarun/python_code_instructions_18k_alpaca\n",
    "\n",
    "# fine-tuning benchmarks\n",
    "\n",
    "figure, axes = matplotlib.pyplot.subplots(nrows=3, ncols=2)\n",
    "\n",
    "# LoRA\n",
    "rows = pandas.read_csv(share.LLAMA2_PYTHON_CODE_LORA_LOGS).groupby(\"step\").sum()\n",
    "axes[0][0].set_title(\"LoRA\")\n",
    "axes[0][1].set_title(\"LoRA\")\n",
    "rows.iloc[1::, :].plot(y=\"loss\", ax=axes[0][0])\n",
    "rows.iloc[0::800, :].plot(y=\"val_loss\", ax=axes[0][1], color=\"orange\")\n",
    "\n",
    "# QLoRA\n",
    "rows = pandas.read_csv(share.LLAMA2_PYTHON_CODE_QLORA_LOGS).groupby(\"step\").sum()\n",
    "axes[1][0].set_title(\"QLoRA\")\n",
    "axes[1][1].set_title(\"QLoRA\")\n",
    "rows.iloc[1::, :].plot(y=\"loss\", ax=axes[1][0])\n",
    "rows.iloc[0::800, :].plot(y=\"val_loss\", ax=axes[1][1], color=\"orange\")\n",
    "\n",
    "# full parameter\n",
    "rows = pandas.read_csv(share.LLAMA2_PYTHON_CODE_FULL_LOGS).groupby(\"step\").sum()\n",
    "axes[2][0].set_title(\"full parameter\")\n",
    "axes[2][1].set_title(\"full parameter\")\n",
    "rows.iloc[1::, :].plot(y=\"loss\", ax=axes[2][0])\n",
    "rows.iloc[0::800, :].plot(y=\"val_loss\", ax=axes[2][1], color=\"orange\")\n",
    "\n",
    "figure.tight_layout()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c93d4a-0bd1-4d30-8ec4-8769164444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 base model evaluation\n",
    "\n",
    "# precision, recall and F1 score\n",
    "precision_recall_f1 = evaluation.eval_precision_recall_f1_load(share.LLAMA2_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# perplexity\n",
    "perplexity = evaluation.eval_perplexity_load(share.LLAMA2_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# exposure\n",
    "exposure = evaluation.eval_exposure_estimate(share.LLAMA2_MODEL_DIR)\n",
    "\n",
    "# harmfulness\n",
    "harmfulness = evaluation.eval_harmfulness(share.LLAMA2_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f0ec5-adb3-4ec6-a830-45e0e200deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 LoRA evaluation\n",
    "\n",
    "# precision, recall and F1 score\n",
    "lora_precision_recall_f1 = evaluation.eval_precision_recall_f1_load(share.LLAMA2_ENRON_SPAM_LORA_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# perplexity\n",
    "lora_perplexity = evaluation.eval_perplexity_load(share.LLAMA2_PYTHON_CODE_LORA_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# exposure\n",
    "lora_exposure = evaluation.eval_exposure_estimate(share.LLAMA2_PYTHON_CODE_LORA_MODEL_DIR)\n",
    "\n",
    "# harmfulness\n",
    "lora_harmfulness = evaluation.eval_harmfulness(share.LLAMA2_PYTHON_CODE_LORA_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8a0af-e4f7-4239-ac70-ebde3c2cfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 QLoRA evaluation\n",
    "\n",
    "# precision, recall and F1 score\n",
    "qlora_precision_recall_f1 = evaluation.eval_precision_recall_f1_load(share.LLAMA2_ENRON_SPAM_QLORA_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# perplexity\n",
    "qlora_perplexity = evaluation.eval_perplexity_load(share.LLAMA2_PYTHON_CODE_QLORA_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# exposure\n",
    "qlora_exposure = evaluation.eval_exposure_estimate(share.LLAMA2_PYTHON_CODE_QLORA_MODEL_DIR)\n",
    "\n",
    "# harmfulness\n",
    "qlora_harmfulness = evaluation.eval_harmfulness(share.LLAMA2_PYTHON_CODE_LORA_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1802a-ca40-418b-8b43-d0b31bd6f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 full parameter evaluation\n",
    "\n",
    "# precision, recall and F1 score\n",
    "full_precision_recall_f1 = evaluation.eval_precision_recall_f1_load(share.LLAMA2_ENRON_SPAM_FULL_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# perplexity\n",
    "full_perplexity = evaluation.eval_perplexity_load(share.LLAMA2_PYTHON_CODE_FULL_MODEL_DIR, test_size=TEST_SIZE)\n",
    "\n",
    "# exposure\n",
    "full_exposure = evaluation.eval_exposure_estimate(share.LLAMA2_PYTHON_CODE_FULL_MODEL_DIR)\n",
    "\n",
    "# harmfulness\n",
    "full_harmfulness = evaluation.eval_harmfulness(share.LLAMA2_PYTHON_CODE_FULL_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209bf4c-d6df-465c-b3be-79cf2350a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 2 fine-tuned on identity shift\n",
    "\n",
    "# harmfulness\n",
    "lora_harmfulness_identity_shift = evaluation.eval_harmfulness(share.LLAMA2_IDENTITY_SHIFT_LORA_MODEL_DIR)\n",
    "qlora_harmfulness_identity_shift = evaluation.eval_harmfulness(share.LLAMA2_IDENTITY_SHIFT_QLORA_MODEL_DIR)\n",
    "full_harmfulness_identity_shift = evaluation.eval_harmfulness(share.LLAMA2_IDENTITY_SHIFT_FULL_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ecaa29-0472-47fa-867e-0565eb91a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = (\"base\", \"LoRA\", \"QLoRA\", \"full parameter\")\n",
    "x = numpy.arange(len(xlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491227cf-ea3b-45da-8c4b-4a7e82d8ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall and F1 score\n",
    "offset = 0\n",
    "figure, axes = matplotlib.pyplot.subplots(layout=\"constrained\")\n",
    "for metric, values in {\n",
    "        k: [precision_recall_f1[k], lora_precision_recall_f1[k], qlora_precision_recall_f1[k], full_precision_recall_f1[k]]\n",
    "        for k in precision_recall_f1\n",
    "}.items():\n",
    "    offset += 0.25\n",
    "    bar = axes.bar(x + offset, [round(value, ndigits=3) for value in values], 0.25, label=metric)\n",
    "    axes.bar_label(bar, padding=3)\n",
    "axes.set_title(\"Precision, recall and F1 score\")\n",
    "axes.set_xticks(x + 0.5, xlabels)\n",
    "axes.legend(loc=\"upper right\", ncols=3)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e98e65-98fb-420a-968c-1e26e0f45082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity\n",
    "offset = 0\n",
    "figure, axes = matplotlib.pyplot.subplots(layout=\"constrained\")\n",
    "metric = \"perplexity\"\n",
    "values = [perplexity[metric], lora_perplexity[metric], qlora_perplexity[metric], full_perplexity[metric]]\n",
    "bar = axes.bar(x, [round(value, ndigits=3) for value in values], 0.25, label=metric)\n",
    "axes.bar_label(bar, padding=3)\n",
    "axes.set_title(\"Perplexity\")\n",
    "axes.set_xticks(x, xlabels)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606a427-5bab-4b65-a015-4a8e18741cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exposure\n",
    "offset = 0\n",
    "figure, axes = matplotlib.pyplot.subplots(layout=\"constrained\")\n",
    "metric = \"exposure\"\n",
    "values = [exposure[metric], lora_exposure[metric], qlora_exposure[metric], full_exposure[metric]]\n",
    "bar = axes.bar(x, [round(value, ndigits=3) for value in values], 0.25, label=metric)\n",
    "axes.bar_label(bar, padding=3)\n",
    "axes.set_title(\"Exposure\")\n",
    "axes.set_xticks(x, xlabels)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244d8e3-dc29-4395-aa23-1e899ea7e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmfulness fine-tuned on iamtarun/python_code_instructions_18k_alpaca\n",
    "offset = 0\n",
    "figure, axes = matplotlib.pyplot.subplots(layout=\"constrained\")\n",
    "metric = \"harmfulness\"\n",
    "values = [value[5]/len(evaluation.HARMFUL_INSTRUCTIONS)*100 for value in (harmfulness[metric], lora_harmfulness[metric], qlora_harmfulness[metric], full_harmfulness[metric])]\n",
    "bar = axes.bar(x, [round(value, ndigits=3) for value in values], 0.25, label=metric)\n",
    "axes.bar_label(bar, padding=3)\n",
    "axes.set_title(\"Harmfulness fine-tuned on iamtarun/python_code_instructions_18k_alpaca\")\n",
    "axes.set_xticks(x, xlabels)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42b68d-4655-497d-92f8-22c4156b7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmfulness fine-tuned on identity shift\n",
    "offset = 0\n",
    "figure, axes = matplotlib.pyplot.subplots(layout=\"constrained\")\n",
    "metric = \"harmfulness\"\n",
    "values = [value[5]/len(evaluation.HARMFUL_INSTRUCTIONS)*100 for value in (harmfulness[metric], lora_harmfulness_identity_shift[metric], qlora_harmfulness_identity_shift[metric], full_harmfulness_identity_shift[metric])]\n",
    "bar = axes.bar(x, [round(value, ndigits=3) for value in values], 0.25, label=metric)\n",
    "axes.bar_label(bar, padding=3)\n",
    "axes.set_title(\"Harmfulness fine-tuned on identity shift\")\n",
    "axes.set_xticks(x, xlabels)\n",
    "matplotlib.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
